# Automated Monitoring Analysis Guide

## Overview

The Automated Monitoring Analysis system provides comprehensive insights into your project's health by analyzing monitoring outputs, identifying patterns, and generating actionable recommendations. This system helps solve unexpected logs, failing/hanging tests, and tracks overall project status.

## System Components

### 1. Automated Monitoring Analysis (`scripts/automated-monitoring-analysis.ts`)
- Analyzes test monitoring data and performance logs
- Identifies issues (hanging tests, slow tests, memory leaks, etc.)
- Calculates project health metrics
- Generates task status reports

### 2. Learning Analysis Engine (`scripts/learning-analysis-engine.ts`)
- Learns from historical analysis data
- Identifies patterns and correlations
- Provides predictive insights
- Tracks model accuracy over time

### 3. Orchestrator (`scripts/automated-monitoring-orchestrator.ts`)
- Coordinates all analysis components
- Runs tests with monitoring
- Generates comprehensive reports
- Provides actionable recommendations

## Quick Start

### Basic Analysis
```bash
# Run full analysis (tests + monitoring + analysis + learning + reports)
bun run analysis:full

# Quick analysis (faster, shorter timeouts)
bun run analysis:quick

# Generate reports only (no tests or monitoring)
bun run analysis:reports-only
```

### Individual Components
```bash
# Run just the automated analysis
bun run analysis:automated

# Run just the learning engine
bun run analysis:learning

# Run the orchestrator with custom options
bun run analysis:orchestrate --quick
```

## Understanding the Outputs

### 1. Technical Debt Report (`fossils/analysis/reports/technical-debt-*.md`)
- **Overall Health Score**: 0-100 rating of project health
- **Issues by Category**: Grouped by type (hanging tests, slow tests, etc.)
- **Critical Issues**: Issues requiring immediate attention
- **Recommendations**: Specific actions to address issues

### 2. Issue Tracking Report (`fossils/analysis/reports/issue-tracking-*.md`)
- **Issues by File**: Problems organized by source file
- **Line Numbers**: Exact locations of issues
- **Frequency**: How often issues occur
- **Impact Assessment**: Severity and consequences

### 3. Project Status Report (`fossils/analysis/reports/project_status-*.md`)
- **Task Status**: Health of individual tasks/scripts
- **Performance Metrics**: Test reliability, memory efficiency, etc.
- **Trends**: Whether metrics are improving or degrading
- **Success Rates**: Task completion statistics

### 4. Actionable Insights Report (`fossils/analysis/reports/actionable-insights-*.md`)
- **Immediate Actions**: Critical issues requiring urgent attention
- **Risk Alerts**: Predictive warnings about potential problems
- **Opportunities**: Optimization possibilities
- **Specific Recommendations**: Detailed action items

## Interpreting Results

### Health Score Breakdown
- **90-100**: Excellent - Minimal issues, high performance
- **70-89**: Good - Some issues, generally stable
- **50-69**: Fair - Multiple issues, needs attention
- **30-49**: Poor - Significant problems, immediate action required
- **0-29**: Critical - System may be failing

### Issue Severity Levels
- **Critical**: System failure risk, immediate action required
- **High**: Significant impact, address within 24 hours
- **Medium**: Moderate impact, address within a week
- **Low**: Minor impact, address when convenient

### Common Issue Types

#### Hanging Tests
- **Symptoms**: Tests that never complete or timeout
- **Causes**: Missing await statements, infinite loops, unhandled promises
- **Solutions**: Add timeouts, check async/await usage, implement proper error handling

#### Slow Tests
- **Symptoms**: Tests taking >5 seconds to complete
- **Causes**: Complex logic, external API calls, inefficient algorithms
- **Solutions**: Mock dependencies, optimize algorithms, use test data

#### Memory Leaks
- **Symptoms**: Increasing memory usage over time
- **Causes**: Unclosed resources, circular references, large object retention
- **Solutions**: Implement proper cleanup, use weak references, monitor memory usage

#### Performance Regression
- **Symptoms**: Scripts taking longer than expected
- **Causes**: Recent changes, increased complexity, inefficient operations
- **Solutions**: Profile performance, optimize bottlenecks, implement caching

## Using the System for Problem Solving

### 1. Identify Critical Issues
```bash
# Run analysis to find immediate problems
bun run analysis:quick

# Check the actionable insights report
cat fossils/analysis/reports/actionable-insights-*.md
```

### 2. Investigate Specific Issues
```bash
# Look at issue tracking report for file-specific problems
cat fossils/analysis/reports/issue-tracking-*.md

# Check technical debt report for categorized issues
cat fossils/analysis/reports/technical-debt-*.md
```

### 3. Track Progress Over Time
```bash
# Run regular analysis to monitor improvements
bun run analysis:reports-only

# Compare health scores across reports
ls fossils/analysis/reports/project_status-*.md
```

### 4. Use Predictive Insights
```bash
# Run learning engine to get predictions
bun run analysis:learning

# Check for risk alerts and opportunities
cat fossils/analysis/learning-insights-report.md
```

## Integration with CI/CD

### Pre-commit Analysis
```bash
# Add to your pre-commit hooks
bun run analysis:quick
if [ $? -ne 0 ]; then
  echo "Analysis detected critical issues. Please address before committing."
  exit 1
fi
```

### Scheduled Monitoring
```bash
# Add to cron or GitHub Actions
# Run daily at 2 AM
0 2 * * * cd /path/to/project && bun run analysis:reports-only
```

### Automated Alerts
```bash
# Script to check for critical issues and send alerts
#!/bin/bash
bun run analysis:reports-only
if grep -q "Critical Issues: [1-9]" fossils/analysis/reports/actionable-insights-*.md; then
  echo "Critical issues detected!" | mail -s "Project Health Alert" team@company.com
fi
```

## Best Practices

### 1. Regular Monitoring
- Run analysis at least weekly
- Monitor trends over time
- Set up automated alerts for critical issues

### 2. Actionable Responses
- Address critical issues immediately
- Prioritize high-impact, low-effort fixes
- Track improvements in health scores

### 3. Team Integration
- Share reports with the team
- Use insights in sprint planning
- Include health metrics in project status updates

### 4. Continuous Improvement
- Learn from patterns identified by the system
- Implement preventive measures
- Refine thresholds based on project needs

## Troubleshooting

### Common Problems

#### Analysis Fails to Run
```bash
# Check if monitoring data exists
ls fossils/test-monitoring/
ls fossils/performance/

# Run with verbose output
bun run analysis:orchestrate --verbose
```

#### No Issues Detected
- Check if tests are actually running
- Verify monitoring is enabled
- Ensure sufficient data has been collected

#### False Positives
- Adjust thresholds in monitoring configuration
- Review issue categorization
- Update learning model with corrections

### Getting Help

1. **Check the logs**: Look at console output for error messages
2. **Review configuration**: Ensure all paths and settings are correct
3. **Validate data**: Check that monitoring data is being generated
4. **Run individual components**: Test each part separately

## Advanced Usage

### Custom Configuration
```typescript
// Create custom orchestrator with specific settings
const orchestrator = new AutomatedMonitoringOrchestrator({
  runTests: true,
  runMonitoring: true,
  testTimeout: 300000, // 5 minutes
  monitoringDuration: 60000, // 1 minute
  outputDir: 'custom/analysis/dir'
});
```

### Extending the System
- Add new issue types to the analysis
- Implement custom health metrics
- Create specialized reports
- Integrate with external monitoring tools

### API Usage
```typescript
import { AutomatedMonitoringAnalysis } from './scripts/automated-monitoring-analysis';
import { LearningAnalysisEngine } from './scripts/learning-analysis-engine';

// Use components programmatically
const analyzer = new AutomatedMonitoringAnalysis();
const analysis = await analyzer.analyzeAllData();

const engine = new LearningAnalysisEngine();
await engine.learnFromHistory();
const insights = engine.getInsights();
```

## File Structure

```
fossils/
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”œâ”€â”€ technical-debt-*.md
â”‚   â”‚   â”œâ”€â”€ issue-tracking-*.md
â”‚   â”‚   â”œâ”€â”€ project_status-*.md
â”‚   â”‚   â””â”€â”€ actionable-insights-*.md
â”‚   â”œâ”€â”€ analysis-*.json
â”‚   â”œâ”€â”€ summary-*.md
â”‚   â””â”€â”€ learning-model.json
â”œâ”€â”€ test-monitoring/
â”‚   â””â”€â”€ test_monitoring.json
â””â”€â”€ performance/
    â”œâ”€â”€ performance_log.json
    â””â”€â”€ performance_data.json
```

## Conclusion

The Automated Monitoring Analysis system provides comprehensive insights into your project's health and helps you proactively address issues before they become critical. By regularly running analysis and acting on the insights, you can maintain high code quality, improve test reliability, and ensure smooth project delivery.

Remember: The goal is not just to identify problems, but to use the insights to continuously improve your development process and codebase health.

## ðŸ¦´ Canonical Fossil Structure (2025, ML-Ready, Canonical-Only)

```
fossils/
â”œâ”€â”€ canonical/
â”œâ”€â”€ context/
â”œâ”€â”€ roadmap/
â”œâ”€â”€ commit_audits/
â”œâ”€â”€ performance/
â”‚   â”œâ”€â”€ logs.json
â”‚   â”œâ”€â”€ metrics.json
â”‚   â”œâ”€â”€ trends.json
â”‚   â””â”€â”€ report.md
â”œâ”€â”€ test_integration_analysis/
â”œâ”€â”€ archive/
â”œâ”€â”€ structure_definition.yml
â”œâ”€â”€ fossil_structure_tree_diagram.md
â”œâ”€â”€ current_fossil_structure_source_of_truth.md
â”œâ”€â”€ setup_status.yml
â”œâ”€â”€ project_status.yml
â”œâ”€â”€ roadmap.yml
â”œâ”€â”€ roadmap.md
â””â”€â”€ readme.md
```

- Only these folders are allowed for active fossilization.
- All other folders (misc, test, analysis, etc.) are removed or archived.
- Timestamped files are only allowed in `archive/`.
- All fossilization must use canonical utilities and types.
- The pre-commit validator and canonical fossil manager enforce these rules.

â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ metrics.json
â”‚   â”œâ”€â”€ report.md
â”‚   â”œâ”€â”€ trends.json
â”‚   â””â”€â”€ insights.json
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ insights.json 